#summary Introduction to PyOTK and examples.

= Accessing the OTK++ interfaces from Python =

The key idea of the PyOTK is to implement seamless interface for the OTK++ classes. That is, the syntax for calling the OTK++ classes and methods from the Python side has as identical syntax with the corresponding C++ code as possible. This can be very conveniently done with Boost.Python. 

The facilities for using the OTK++ classes and methods from Python are implemented in the 'native' module: 

{{{
>>> from pyotk.native import *
}}}

The 'testproblems' module contains the test problem set given by More, Garbow and Hillstrom: 

{{{
>>> from pyotk.testproblems import *
}}}

The Python methods for instantiating OTK++ object have a similar syntax with their C++ counterparts. For example, a GSL 'vector_bfgs2' solver and an instance of an two-dimensional Rosenbrock test function from the 'testproblems' module can be instantiated as follows:

{{{
>>> s = GSLfdfsolver('vector_bfgs2')
>>> f = ExtendedRosenbrock(n=2)
}}}

The starting point is specified as a tuple, and the stopping criterion can be instantiated with constructors similar to those in the C++ library: 

{{{
>>> x0 = (-1.2, 1)
>>> sc = GradNormTest(eps=1e-8)
}}}

minimize is the driver routine for calling OTK++ algorithms from PyOTK. Its arguments are the solver to use, its parameters, the objective function, stopping criterion, starting point, constraints, and output verbosity level (+optional arguments):

{{{
>>> results = minimize(s, DefaultSolverSetup(), f.otk_instance,
                       sc, x0, NoConstraints(), 2, False)
}}}

In this case, the minimization routine produces the following output with a list of each iterate and the final value on termination of the algorithm:

{{{
k     x1                  x2                  f(x1,x2)
0     -1.2                1                   24.2
1     -1.03028            1.06927             4.12812
2     -0.9292             0.826945            3.8548
3     -0.784035           0.555324            3.53547
4     -0.328604           0.0804101           1.8412
5     -0.339617           0.108005            1.79995
6     -0.159493           -0.00795583         1.45594
7     0.039584            -0.0375634          1.07552
8     0.0558816           0.00701654          0.892876
9     0.202199            0.0184589           0.686777
10    0.306646            0.0619552           0.583631
11    0.844603            0.710851            0.0247749
12    0.843606            0.710517            0.0245923
13    0.916852            0.83491             0.0101719
14    0.990373            0.984279            0.00127586
15    1.00684             1.01406             5.79134e-05
16    0.99951             0.999178            2.75314e-06
17    0.999922            0.999841            6.90778e-09
18    1                   1                   8.46378e-11
19    1                   1                   3.10683e-13

Minimizer:                         (1,1)
Minimum value:                     4.54419e-20
Minimum gradient:                  (-8.48204e-09,4.20621e-09)
iterations:                        20
function evaluations:              0
gradient evaluations:              0 (0)
}}}

In addition to the above output, the results are also stored in the returned 'results' object. In this case, it contains the following fields:

|| Field || Description ||
|| input || used input parameters ||
|| converged || was the stopping criterion satisfied on termination ||
|| num_iter || number of iterations ||
|| num_func_eval || number of function evaluations ||
|| num_grad_eval || number of gradient evaluations ||
|| states || detailed information about each iterate ||

If the last parameter of the 'minimize' method is set to true, a special time test 
mode will be enabled. In this case, any time-consuming operations such as storing the results is skipped, and only computation time is measured. The computed time will be stored to the 'time' attribute of the 'results' object.

Download example: [http://users.utu.fi/seppul/otkpp/examples/pyotk/driver_example.py driver_example.py]

= Visualization =

PyOTK uses Matplotlib for plotting. The following visualizations for the results of minimization algorithms are currently implemented:

  * drawing iterates of an algorithm on contours of test function
  * drawing convergence plots of algorithms
  * computing the Dolan and More performance profiles

<img src="images/contour_with_iterates.png">
<img src="images/convergence_plot.png">
<img src="images/perfprof.png">

== 'pyotk.plot2d' module ==

The 'plot2d' module implements methods 
for visualizing the iteration of a solver. 
For a given function of two variables, 
the iterates produced by a solver can be plotted 
on top of contours of the objective function.

The following example demonstrates minimizing the Beale test function and plotting the results using the 'plot_iterates_on_contours' method.

{{{
from pyotk.native import *
from pyotk.plot2d import *
from pyotk.testproblems import *

f = Beale()
x1 = f.plot_spec.x_range[0]
x2 = f.plot_spec.x_range[1]
y1 = f.plot_spec.y_range[0]
y2 = f.plot_spec.y_range[1]
z1 = f.plot_spec.z_range[0]
z2 = f.plot_spec.z_range[1]

s = LinminBFGS()
results = minimize(s, DefaultSolverSetup(), f.otk_instance, f.stopcrit, f.x0, NoConstraints(), 0, False)
plot_iterates_on_contours(results, x1, x2, y1, y2, z1, z2)
}}}

Download example: [http://users.utu.fi/seppul/otkpp/examples/pyotk/plot2d_example.py plot2d_example.py]

== 'pyotk.convergence' module ==

A convergence plot represents the given quantity 
(e.g. distance to an a-priori known minimizer) as a 
function of number of used iterations. The 
'convergence' module implements methods 
drawing convergence plots of one or more 
algorithms into the same figure.

The first example demonstrates using the 'compare_convergence' method for comparing convergence rates of different algorithms.

{{{
from pyotk.native import *
from pyotk.testproblems import *
from pyotk.convergence import *

S = [ LinminBFGS(BFGSLmType.morethuente),
      LinminBFGS(BFGSLmType.fletcher),
      ConjGradMT(ConjGradType.FR),
      ConjGradMT(ConjGradType.PR) ]

P = [ Beale(),
      HelicalValley(),
      Wood(),
      ExtendedRosenbrock(n=10) ]

compare_convergence(S, P);
}}}

The second example demonstrates using the 'convergence_plot' method for plotting gradient norm and objective function value as a function of used iterations.

{{{
from pyotk.native import *
from pyotk.testproblems import *
from pyotk.convergence import *

tf = ExtendedRosenbrock(8)
results = minimize(GSLfdfsolver('vector_bfgs2'),
                    DefaultSolverSetup(), tf.otk_instance,
                    GradNormTest(eps=1e-8), tf.x0,
                    NoConstraints(), 0, False)
quantities = ['gradnorm', 'funcval']

convergence_plot(results, quantities)
}}}

Download example 1: [http://users.utu.fi/seppul/otkpp/examples/pyotk/convergence_example_1.py convergence_example_1.py]

Download example 2: [http://users.utu.fi/seppul/otkpp/examples/pyotk/convergence_example_2.py convergence_example_2.py]

== 'pyotk.perfprof' module ==

The Dolan and More performance profiles are commonly 
used for comparing performance of different algorithms. 
For a given set of test problems and a given set of 
solvers, these performance profiles can be computed 
by using the 'perfprof' module.

The following example demonstrates using the 'performance_profile' method for computing performance profiles. The list S contains the solvers to use, and the list P contains the set of test problems.

{{{
from pyotk.native import *
from pyotk.testproblems import *
from pyotk.perfprof import *

S = [ ConjGradMT(ConjGradType.FR),
      ConjGradMT(ConjGradType.PR),
      SteihaugSR1(),
      LinminBFGS(BFGSLmType.morethuente) ]

P = [ PowellBadlyScaled(),
      BrownBadlyScaled(),
      Beale(),
      HelicalValley(),
      Gaussian(),
      Box(m=5),
      Wood(),
      BrownDennis(m=20),
      BiggsEXP6(m=13),
      Watson(n=6),
      ExtendedRosenbrock(n=10),
      ExtendedPowellSingular(n=12),
      PenaltyFunctionI(n=10),
      PenaltyFunctionII(n=10),
      VariablyDimensioned(n=10),
      Trigonometric(n=5),
      ChebyQuad(n=8, m=8) ]

performance_profile(S, P, True)
}}}

Download example: [http://users.utu.fi/seppul/otkpp/examples/pyotk/perfprof_example.py perfprof_example.py]